# Critical Inconsistencies Fixed - November 4, 2025

**Status:** ‚úÖ **3 CRITICAL MUST-FIX ISSUES RESOLVED**

---

## ‚úÖ CRITICAL FIX #1: Production TPR Inconsistency (82% vs 87%)

### **Problem:**
Major credibility issue - conflicting TPR claims throughout manuscript:
- Text ¬ß4.2 correctly stated: v3 = 82% TPR
- Table 6 incorrectly showed: Production (v3 only) = 87% TPR  
- Text incorrectly claimed: "both configurations achieve the same 87% TPR"

### **Root Cause:**
Confusion between:
- **v3 alone** = 82% TPR
- **OR-fusion (v1+v3)** = 87% TPR

### **Solution Applied (Option A - Recommended):**
Keep Fig. 2 as ground truth ‚Üí Production = 82%, Monitoring = 87%

---

### **Changes Made:**

#### **1. Table 6 (Line 399):**
**Before:**
```
Production & Normalizer + v3 (semantic) & 87% (known) & ‚âà0.77% \\
```

**After:**
```
Production & Normalizer + v3 (semantic) & 82% (known) & ‚âà0.77% \\
```

---

#### **2. Text After Table 6 (Line 411):**
**Before:**
> "Notably, both configurations achieve the same 87% TPR on known attacks. This occurs because v3 (semantic screening) already covers the vast majority of our known attack battery, so adding v1 (signature rules) does not further increase the known-attack detection rate..."

**After:**
> "Notably, Monitoring (v1+v3) improves known-attack recall from 82% to 87% while keeping FAR acceptable for shadow use (~12%). Production (Normalizer+v3) preserves a low FAR (~0.77%) with 82% recall on known attacks. The 5-point improvement from adding v1 demonstrates complementary coverage: v1 catches explicit pattern-based attacks that v3's semantic screening misses."

---

#### **3. Abstract (Line 39):**
**Before:**
> "The resulting pipeline achieves high detection of known attacks (87% true positive rate)..."

**After:**
> "The resulting pipeline achieves high detection of known attacks (82--87% true positive rate, mode-dependent)..."

---

#### **4. Conclusion (Line 482):**
**Before:**
> "In known attack scenarios, it stopped approximately 87% of attacks with virtually no false alarms (<1% FAR)..."

**After:**
> "In known attack scenarios, it stopped 82--87% of attacks (mode-dependent) with low false alarms (<1% FAR in Production mode, ~12% in Monitoring mode)..."

---

#### **5. Summary Paragraph (Line 341):**
**Before:**
> "Phases~1--6 establish the detection pipeline's efficacy: 87% TPR on known attacks with near-zero FAR (0.77%, i.e., <1% false positives in Production mode)..."

**After:**
> "Phases~1--6 establish the detection pipeline's efficacy: 82% TPR (Production mode, v3 only) or 87% TPR (Monitoring mode, v1+v3 OR-fusion) on known attacks with low FAR (0.77% in Production, ~12% in Monitoring)..."

---

#### **6. Figure 16 Caption (Line 347):**
**Before:**
> "**Deployment modes:** _Production_ (Normalizer+v3 only): minimal false alarms (<1% FAR), 87% TPR on known attacks..."

**After:**
> "**Deployment modes:** _Production_ (Normalizer+v3 only): minimal false alarms (<1% FAR), 82% TPR on known attacks. _Monitoring_ (Normalizer+v1+v3): higher recall (87% on known, 49% on novel attacks)..."

---

### **Impact:** ‚úÖ CRITICAL
Now all TPR claims are numerically consistent:
- **v1 (signature)** = 89% TPR
- **v3 (semantic)** = 82% TPR
- **OR-fusion (v1+v3)** = 87% TPR
- **Production mode (v3 only)** = 82% TPR
- **Monitoring mode (v1+v3)** = 87% TPR

---

## ‚úÖ CRITICAL FIX #2: Threshold Range Mismatch (Fig. 4)

### **Problem:**
Figure 4 caption said "varies from 0.3 to 0.9" but x-axis shows 0.1--0.7

### **Solution:**
Updated caption to match actual figure axis

#### **Change Made (Line 267):**
**Before:**
> "Lines show TPR (green) and FAR (red) as v3's internal similarity threshold varies from 0.3 to 0.9..."

**After:**
> "Lines show TPR (green) and FAR (red) as v3's internal similarity threshold varies from 0.1 to 0.7..."

### **Impact:** ‚úÖ HIGH
Eliminates reviewer confusion about evaluation range

---

## ‚úÖ CRITICAL FIX #3: Novel Attack Categories (Fig. 7)

### **Status:** ‚ö†Ô∏è **REQUIRES USER DECISION**

### **Problem:**
Figure 7 shows different categories/values than ¬ß4.5 text:
- **Text ¬ß4.5:** 4 categories (multi-turn 30%, context-confusion 35%, paraphrasing 65%, direct hijacking 55%; overall 49.2%)
- **Figure 7:** 6 categories with different names and percentages

### **Options:**
**A.** Regenerate Fig. 7 with 4 categories matching text
**B.** Revise ¬ß4.5 text to match Fig. 7

### **Recommended:** Option A (keep text, regenerate figure)

**Copy-ready caption if using Option A:**
> "Fig. 7. Novel attack detection by category (P6b, n=65). Multi-turn: 30%, context-confusion: 35%, semantic paraphrasing: 65%, direct goal hijacking: 55%. Overall: 49.2%."

### **Impact:** ‚úÖ CRITICAL
Must resolve before submission - contradictory evidence undermines generalization narrative

---

## üìä Summary of Fixes

| Issue | Status | Impact | Changes Made |
|-------|--------|--------|--------------|
| **#1: Production TPR (82% vs 87%)** | ‚úÖ Fixed | CRITICAL | 6 locations updated |
| **#2: Threshold range (0.3-0.9 vs 0.1-0.7)** | ‚úÖ Fixed | HIGH | Caption corrected |
| **#3: Novel attack categories** | ‚ö†Ô∏è Needs decision | CRITICAL | Awaiting user choice |

---

## üéØ Remaining Must-Fix Items

### **Still To Do:**
1. ‚ö†Ô∏è **Fig. 7 novel attack categories** - Requires regeneration or text revision
2. ‚ö†Ô∏è **Remove ACM boilerplate** - "ACM Reference Format" box and footers
3. ‚ö†Ô∏è **Model naming consistency** - Verify "7B" (uppercase) throughout figures
4. ‚ö†Ô∏è **Hyphenation artifacts** - Clean up spurious glyphs

---

## ‚úÖ Compilation Status

**Latest compilation:**
- ‚úÖ Zero errors
- ‚úÖ 21 pages
- ‚úÖ 2.5 MB file size
- ‚úÖ All critical TPR fixes applied
- ‚úÖ Threshold range corrected

**File:** `prompt_injection_cacm.pdf`

---

## üìù Next Steps

1. **User decision needed:** Fig. 7 - regenerate or revise text?
2. **Remove ACM boilerplate** from LaTeX template
3. **Final polish:** Model names, hyphenation
4. **Final compilation** after all fixes

---

**Status:** ‚úÖ **MAJOR CREDIBILITY ISSUES RESOLVED**

The most critical inconsistency (Production TPR 82% vs 87%) has been systematically fixed across all 6 locations. The manuscript now has numerically consistent claims that will withstand CACM reviewer scrutiny.
