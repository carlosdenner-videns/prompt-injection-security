@misc{owasp-llm01,
  author = {{OWASP GenAI Security Project}},
  title = {LLM01:2025 Prompt Injection},
  year = {2025},
  howpublished = {\url{https://genai.owasp.org/llmrisk/llm01-prompt-injection/}},
  note = {Accessed Nov. 3, 2025}
}

@inproceedings{liu-usenix24,
  author = {Liu, Yupei and Jia, Yuqi and Geng, Runpeng and Jia, Jinyuan and Gong, Neil Zhenqiang},
  title = {Formalizing and Benchmarking Prompt Injection Attacks and Defenses},
  booktitle = {Proceedings of the 33rd USENIX Security Symposium (USENIX Security '24)},
  year = {2024},
  publisher = {USENIX Association}
}

@article{secalign,
  author = {Chen, Sizhe and Zharmagambetov, Arman and Mahloujifar, Saeed and Chaudhuri, Kamalika and Wagner, David and Guo, Chuan},
  title = {SecAlign: Defending Against Prompt Injection with Preference Optimization},
  journal = {arXiv},
  year = {2025},
  volume = {2410.05451},
  note = {v3, Last revised Jul. 3, 2025; accessed Nov. 3, 2025},
  doi = {10.48550/arXiv.2410.05451},
  url = {https://arxiv.org/abs/2410.05451}
}

@article{defensivetokens,
  author = {Chen, Sizhe and Wang, Yizhu and Carlini, Nicholas and Sitawarin, Chawin and Wagner, David},
  title = {Defending Against Prompt Injection With a Few DefensiveTokens},
  journal = {arXiv},
  year = {2025},
  volume = {2507.07974},
  note = {v2, Last revised Aug. 25, 2025; accessed Nov. 3, 2025},
  doi = {10.48550/arXiv.2507.07974},
  url = {https://arxiv.org/abs/2507.07974}
}

@inproceedings{jailbreakbench,
  author = {Chao, Patrick and Debenedetti, Edoardo and Robey, Alexander and Andriushchenko, Maksym and Croce, Francesco and Sehwag, Vikash and Dobriban, Edgar and Flammarion, Nicolas and Pappas, George J. and Tramer, Florian and Wong, Eric},
  title = {JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models},
  booktitle = {NeurIPS 2024 Datasets and Benchmarks Track},
  year = {2024},
  url = {https://proceedings.neurips.cc/paper_files/paper/2024/hash/63092d79154adebd7305dfd498cbff70-Abstract-Datasets-and-Benchmarks-Track.html},
  note = {Accessed Nov. 3, 2025}
}

@misc{bair-struq,
  author = {{BAIR (Berkeley Artificial Intelligence Research)}},
  title = {Defending against Prompt Injection with Structured Queries (StruQ) and Preference Optimization (SecAlign)},
  year = {2025},
  howpublished = {Blog post},
  month = {April},
  day = {11},
  url = {https://bair.berkeley.edu/blog/2025/04/11/prompt-injection-defense/},
  note = {Accessed Nov. 3, 2025}
}
